# music-viz
# http://www.geosci.usyd.edu.au/users/jboyden/vad/
Road Map
Set up the file layout from below
Read in file
Extract intensity, timbre, pitch, rhythm
For each effect
Animation system
Read in an audio file
Create a scene of one color
Decide on times to meet -- Wednesday nights and Friday afternoons

Queue:

Change the scene of one color to another color based on intensity
Change the scene of one color to another color based on timbre
Change the scene of one color to another color based on pitch
Change the scene of one color to another color based on rhythm

NOTE:  The interface should take in a mood, and output an effect (here, a color)

Later:

Load a scene of a small number of object files from online
Decide on mappings between effect and mood element of song, and implement one by one
Effects:
Rain
Northern lights - based on frequency of music
Time of day / sunset / sunrise
Snow
Wind
Night sky and stars
Mood elements: -- global variables
Intensity
Timbre
Pitch: Frequency in Hz, # of cycles per second -- higher frequency == higher pitch
Rhythm:  Beats per minute ()
Make the scene render non-photorealistic rendering ("artsy")
Load some models we've drawn ourselves into the scene
Move the camera left/right/forward/backward depending on time in song
Allow choosing a song from a playlist
Create more scenes, and allow choosing to view a scene from a group of scenes
Create a skybox
Output the mean intensity, timbre, pitch, and rhythm of a song, and output the data of the song
